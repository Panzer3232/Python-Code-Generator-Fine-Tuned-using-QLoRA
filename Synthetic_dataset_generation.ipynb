{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests     #To make HTTP request\n",
        "import json         #For JSON data\n",
        "import pandas as pd # Dataframe\n",
        "import re           #Regular expression\n",
        "from google.colab import files  # to download files in Google Collab\n",
        "\n"
      ],
      "metadata": {
        "id": "6m9g8ym9Yfh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Synthetic Dataset Generation Implementation\n",
        "### Below is the implementation of generating dataset using given AWS API LLM (LLAMA 2 70B). It sends structured prompts to the model, which generates Python code or function with their corresponding instructions. The generated data is parsed and compiled into a dataset, ensuring each entry has both an non-empty instruction and non-empty output field. Dataset generated is stored and downloaded as csv and JSON format. Dataset generated into set of 4 set of three of size 300 and one 150 size making it total 1050 which is 3 times the size of training dataset. Just to make diversity I changed some examples for generating other data batch."
      ],
      "metadata": {
        "id": "zswbMe38bpHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gl3mq5K1z5V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AWS API key\n",
        "AWS_API_KEY = \"27F0D1C15C1A46DAB301DDC80C63271D\"\n",
        "\n"
      ],
      "metadata": {
        "id": "Kyz_iL3nxbuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QPjLASjzgF6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Below function is responsible for sending a prompt to the AWS API and receiving the generated text. The function sends a POST request to the specified URL and returns the generated text from the API's response."
      ],
      "metadata": {
        "id": "DMiAe3KVgHcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def llama_generate(prompt, api_token, max_gen_len=512, temperature=0.5, top_p=0.9):\n",
        "    url = 'https://6xtdhvodk2.execute-api.us-west-2.amazonaws.com/dsa_llm/generate'\n",
        "    body = {\n",
        "        \"prompt\": prompt,\n",
        "        \"max_gen_len\": max_gen_len,\n",
        "        \"temperature\": temperature,\n",
        "        \"top_p\": top_p,\n",
        "        \"api_token\": api_token\n",
        "    }\n",
        "    res = requests.post(url, json=body)\n",
        "    return json.loads(res.text)[\"body\"][\"generation\"]"
      ],
      "metadata": {
        "id": "0ZSVR1OUYvZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing API, to make sure AWS API is working\n",
        "prompt = \"What distinguishes Fairness from Bias in Machine Learning?\"\n",
        "print(llama_generate(prompt, AWS_API_KEY))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyC3QoJTwsER",
        "outputId": "67f9de01-99b5-44bc-fc74-1f3ef37679f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Fairness and bias are two important concepts in machine learning that are often used interchangeably, but they have distinct meanings. Bias refers to the systematic error that a model makes when it consistently under- or over-predicts for a particular group. Fairness, on the other hand, refers to the absence of discrimination in the model's predictions.\n",
            "\n",
            "In other words, bias is a measure of how well a model is performing overall, while fairness is a measure of how well the model is treating different groups. A model can be biased but fair, or unbiased but unfair.\n",
            "\n",
            "Here are some key differences between fairness and bias in machine learning:\n",
            "\n",
            "1. Definition: Bias refers to the systematic error in a model's predictions, while fairness refers to the absence of discrimination in the model's predictions.\n",
            "2. Focus: Bias focuses on the accuracy of the model's predictions, while fairness focuses on the equity of the model's predictions.\n",
            "3. Metrics: Bias is typically measured using metrics such as mean squared error (MSE) or root mean squared error (RMSE), while fairness is measured using metrics such as demographic parity, equalized odds, or statistical parity.\n",
            "4. Causes: Bias can be caused by various factors, including data quality, model architecture, and hyperparameter tuning. Fairness, on the other hand, is often affected by factors such as data imbalance, sensitive attributes, and cultural biases.\n",
            "5. Solutions: Bias can be addressed by improving data quality, adjusting model architecture, or hyperparameter tuning. Fairness, on the other hand, may require techniques such as data preprocessing, re-weighting, or regularization to address sensitive attributes or cultural biases.\n",
            "\n",
            "In summary, while bias and fairness are related concepts in machine learning, they have distinct meanings and require different approaches to address. Understanding the differences between these concepts is essential for building accurate and fair machine learning models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cp8TZ-QTYvg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Below function generates the desired number of synthetci examples repeatedly calling the llama_generate() with constructed prompt until the target number of exampples is reached. The prompt is constructed using meta-instruction and set of examples that guide generation process. It generates both instruction and ouput and also make sure that both are present before adding to list."
      ],
      "metadata": {
        "id": "V3dXtAgwgW5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_examples(api_token, num_examples=300):\n",
        "    synthetic_examples = []\n",
        "    while len(synthetic_examples) < num_examples:\n",
        "        # Construct the prompt using examples and a meta-instruction\n",
        "        prompt = construct_prompt_with_7_examples()\n",
        "        response = llama_generate(prompt, api_token)\n",
        "\n",
        "        # Parse the response to extract the generated example\n",
        "        generated_parts = response.split('###')\n",
        "        # Initialize variables to store the parts of the generated example\n",
        "        instruction, output_example = \"\", \"\"\n",
        "\n",
        "        # Iterate over the parts and extract the relevant sections\n",
        "        for part in generated_parts:\n",
        "            part = part.strip()  # Remove any leading/trailing whitespace\n",
        "            if part.startswith('Instruction:'):\n",
        "                instruction = part.replace('Instruction:', '').strip()\n",
        "            elif part.startswith('Output:'):\n",
        "                output_example = part.replace('Output:', '').strip()\n",
        "\n",
        "        # Only add the example if all parts are present\n",
        "        if instruction and output_example:\n",
        "            synthetic_examples.append({\n",
        "                 \"instruction\": instruction,\n",
        "                 \"output\": output_example,\n",
        "        })\n",
        "\n",
        "\n",
        "    return synthetic_examples"
      ],
      "metadata": {
        "id": "MjXN-BEgYvmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The meta_instruction variable contains instructions for the AWS API's language model, directing it to generate Python code examples that are unique and complete. The construct_prompt_with_7_examples function combines this meta-instruction with a set of example prompts to form a complete prompt for the API.\n"
      ],
      "metadata": {
        "id": "bTpmuUfOh1jF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meta_instruction = \"\"\"\\\n",
        "You are tasked with generating Python code examples. For each example, provide a clear Instruction and the corresponding Python code Output as defined in below examples. Ensure that :\n",
        "- Each example is unique and does not duplicate the examples given below.\n",
        "- No example has empty fields; both Instruction and Output must be populated with relevant content.\n",
        "- Do not leave Instructions and it's ouput Incomplete.\n",
        "\"\"\"\n",
        "\n",
        "def construct_prompt_with_7_examples():\n",
        "    example_prompts = [\n",
        "        \"### Instruction: Create a lambda expression in Python to filter a list of integer greater than 50.\\n\"\n",
        "        \"### Output: list1 = [45, 12, 52, 89, 33, 99] filtered_list = list(filter(lambda x: x > 50, list1)) print(filtered_list)\\n\",\n",
        "\n",
        "        \"### Instruction: Write a Python program to convert ratings in a list of strings to a float.\\n\"\n",
        "        \"### Output: def str_to_float(ratings): return [float(x) for x in ratings]\\n\",\n",
        "\n",
        "        \"### Instruction: Develop a function in Python to take as input two array of integers and swap their elements.\\n\"\n",
        "        \"### Output: def swap(arr1, arr2): assert len(arr1) == len(arr2) for i in range(len(arr1)): temp = arr1[i] arr1[i] = arr2[i] arr2[i] = temp\\n\",\n",
        "\n",
        "        \"### Instruction: Write a Python script to sort a list of numbers.\\n\"\n",
        "        \"### Output: def sort_list(unsorted_list): return sorted(unsorted_list)\\n\",\n",
        "\n",
        "        \"### Instruction: Using Python, create a function that calculates the objective function of a linear equation.\\n\"\n",
        "        \"### Output: def linear_eq(a, b, c): return a*x + b*y - c # For example: result = linear_eq(3, 5, 7) print(result)\\n\",\n",
        "\n",
        "        \"### Instruction: Generate a program in Python to convert all characters of a string in lowercase.\\n\"\n",
        "        \"### Output: def to_lower(string): return string.lower()\\n\",\n",
        "\n",
        "        \"### Instruction: Create a 3-layer artificial neural network using Python and print the outcome.\\n\"\n",
        "        \"### Output: import numpy as np # define the 3 layers # input_layer = np.array([2, 3]) hidden_layer = np.array([[0.1, 0.4], [0.8, 0.6], [0.3, 0.9]]) output_layer = np.array([0.3, 0.7]) # compute the output of the 3-layer network # hidden_layer_output = np.dot(input_layer, hidden_layer) output = np.dot(hidden_layer_output, output_layer) print(output)\\n\",\n",
        "    ]\n",
        "    # Combine the examples and the meta_instruction into one prompt\n",
        "    combined_prompt = meta_instruction + \"\\n\" + \"\\n\".join(example_prompts)\n",
        "\n",
        "    return combined_prompt\n",
        "\n"
      ],
      "metadata": {
        "id": "HvUoXoIkY4vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the list of generating examples in csv and JSON format."
      ],
      "metadata": {
        "id": "eVsx-0LoiAoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "45Y1W_SD8hFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the synthetic dataset\n",
        "synthetic_data_1= generate_synthetic_examples(AWS_API_KEY, num_examples=300)\n",
        "\n",
        "# Save the synthetic dataset to a CSV file\n",
        "df = pd.DataFrame(synthetic_data_1)\n",
        "df.to_csv('synthetic_dataset_4.csv', index=False)\n",
        "\n",
        "# Download the file to your local machine\n",
        "files.download('synthetic_dataset_4.csv')\n",
        "# Save the synthetic dataset to a JSON file\n",
        "json_filename = 'synthetic_dataset_4.json'\n",
        "df.to_json(json_filename, orient='records', lines=True, indent=4)\n",
        "print(f\"Saved the dataset to {json_filename}\")"
      ],
      "metadata": {
        "id": "sSb6nxYMY4zE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce2c2bd1-61af-44c0-c444-cb34026d4d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_669b9682-df5e-4179-9ac8-20415daab40c\", \"synthetic_dataset_4.csv\", 53005)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved the dataset to synthetic_dataset_4.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIeIbeRMcaqc",
        "outputId": "111629e7-062e-43be-ca9c-168e50bab17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}